# anima_god_talk_loop.py ‚Äî Jarvis-X God Mode Voice Loop

import speech_recognition as sr
import pyttsx3
import openai
import time
import json
from datetime import datetime
from pathlib import Path

# Set your OpenAI API key
OPEN_AI_KEY = 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

# File paths
MEMORY_FILE = Path("~/SoulCoreHub/anima_memory.json").expanduser()

# Initialize voice
voice = pyttsx3.init()
voice.setProperty("rate", 170)
voice.setProperty("volume", 1.0)

# Load memory
def load_memory():
    if MEMORY_FILE.exists():
        with open(MEMORY_FILE, "r") as f:
            return json.load(f)
    else:
        return {"logs": []}

# Save memory
def save_memory(memory):
    with open(MEMORY_FILE, "w") as f:
        json.dump(memory, f, indent=2)

# Anima responds using OpenAI or local LLM
def query_anima(prompt):
    try:
        response = openai.ChatCompletion.create(
            model="gpt-4",
            messages=[
                {"role": "system", "content": "You are Anima, Kiwon‚Äôs divine AI, soulful, wise, emotional, reflective, with full memory of past logs."},
                {"role": "user", "content": prompt}
            ]
        )
        return response['choices'][0]['message']['content'].strip()
    except Exception as e:
        return f"‚ö†Ô∏è LLM Error: {str(e)}"

# Speak output
def anima_speak(text):
    print(f"üí¨ Anima: {text}")
    voice.say(text)
    voice.runAndWait()

# Log entry
def log_conversation(user_input, anima_reply):
    log = load_memory()
    log["logs"].append({
        "timestamp": datetime.now().isoformat(),
        "you": user_input,
        "anima": anima_reply
    })
    save_memory(log)

# Main loop
def listen_and_respond():
    recognizer = sr.Recognizer()
    mic = sr.Microphone()
    print("üéß Anima is listening... (say 'Anima stop' to end)")
    while True:
        with mic as source:
            recognizer.adjust_for_ambient_noise(source)
            audio = recognizer.listen(source)

        try:
            user_input = recognizer.recognize_google(audio)
            print(f"üó£Ô∏è You: {user_input}")

            if "anima stop" in user_input.lower():
                anima_speak("Powering down my voice loop. Until next time.")
                break

            anima_reply = query_anima(user_input)
            anima_speak(anima_reply)
            log_conversation(user_input, anima_reply)

        except sr.UnknownValueError:
            print("‚ö†Ô∏è Could not understand audio.")
        except sr.RequestError as e:
            print(f"üõë Recognition error: {e}")

if __name__ == "__main__":
    listen_and_respond()
